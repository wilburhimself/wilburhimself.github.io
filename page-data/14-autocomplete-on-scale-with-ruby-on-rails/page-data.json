{"componentChunkName":"component---src-templates-blog-post-js","path":"/14-autocomplete-on-scale-with-ruby-on-rails/","result":{"data":{"site":{"siteMetadata":{"title":"Wilbur Suero - Software Craftsman","author":"Wilbur Suero"}},"markdownRemark":{"id":"7e456602-3e3d-5fce-adb1-a576f4012fc0","excerpt":"As software engineers, we’re constantly striving to build applications that are not only feature-rich, but also lightning-fast, even in the face of ever-growing…","html":"<p>As software engineers, we’re constantly striving to build applications that are not only feature-rich, but also lightning-fast, even in the face of ever-growing datasets. And when it comes to implementing search functionality - particularly the coveted autocomplete feature - the challenge of maintaining performance can be a real thorn in our sides.</p>\n<p>Enter the humble trie data structure. This unassuming tree-like construct holds the key to unlocking highly efficient prefix-based searches, making it an ideal choice for powering autocomplete in our Ruby on Rails applications. But as our user base grows and our databases swell to the millions, we need to go beyond the basic trie implementation to ensure that our search remains speedy and responsive.</p>\n<p>In this post, we’ll explore a series of performance-focused optimizations that will allow us to harness the power of tries to build an autocomplete solution that can scale to meet the demands of even the most data-hungry applications.</p>\n<h3>The Trie: A Refresher</h3>\n<p>At its core, a trie is a tree-like data structure where each node represents a character in a word or phrase. The beauty of a trie lies in its ability to perform prefix-based searches with lightning-fast speed, making it a perfect fit for autocomplete functionality.</p>\n<p>Here’s a simple implementation of a trie in Ruby:</p>\n<div class=\"gatsby-highlight\" data-language=\"ruby\"><pre class=\"language-ruby\"><code class=\"language-ruby\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">Trie</span>\n  <span class=\"token keyword\">def</span> <span class=\"token method-definition\"><span class=\"token function\">initialize</span></span>\n    <span class=\"token variable\">@root</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token punctuation\">}</span>\n  <span class=\"token keyword\">end</span>\n\n  <span class=\"token keyword\">def</span> <span class=\"token method-definition\"><span class=\"token function\">insert</span></span><span class=\"token punctuation\">(</span>word<span class=\"token punctuation\">)</span>\n    node <span class=\"token operator\">=</span> <span class=\"token variable\">@root</span>\n    word<span class=\"token punctuation\">.</span>each_char <span class=\"token keyword\">do</span> <span class=\"token operator\">|</span>char<span class=\"token operator\">|</span>\n      node<span class=\"token punctuation\">[</span>char<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span><span class=\"token punctuation\">}</span> <span class=\"token keyword\">unless</span> node<span class=\"token punctuation\">.</span>key<span class=\"token operator\">?</span><span class=\"token punctuation\">(</span>char<span class=\"token punctuation\">)</span>\n      node <span class=\"token operator\">=</span> node<span class=\"token punctuation\">[</span>char<span class=\"token punctuation\">]</span>\n    <span class=\"token keyword\">end</span>\n    node<span class=\"token punctuation\">[</span><span class=\"token symbol\">:is_end_of_word</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token boolean\">true</span>\n  <span class=\"token keyword\">end</span>\n\n  <span class=\"token keyword\">def</span> <span class=\"token method-definition\"><span class=\"token function\">search</span></span><span class=\"token punctuation\">(</span>word<span class=\"token punctuation\">)</span>\n    node <span class=\"token operator\">=</span> <span class=\"token variable\">@root</span>\n    word<span class=\"token punctuation\">.</span>each_char <span class=\"token keyword\">do</span> <span class=\"token operator\">|</span>char<span class=\"token operator\">|</span>\n      <span class=\"token keyword\">return</span> <span class=\"token boolean\">false</span> <span class=\"token keyword\">unless</span> node<span class=\"token punctuation\">.</span>key<span class=\"token operator\">?</span><span class=\"token punctuation\">(</span>char<span class=\"token punctuation\">)</span>\n      node <span class=\"token operator\">=</span> node<span class=\"token punctuation\">[</span>char<span class=\"token punctuation\">]</span>\n    <span class=\"token keyword\">end</span>\n    node<span class=\"token punctuation\">.</span>key<span class=\"token operator\">?</span><span class=\"token punctuation\">(</span><span class=\"token symbol\">:is_end_of_word</span><span class=\"token punctuation\">)</span>\n  <span class=\"token keyword\">end</span>\n<span class=\"token keyword\">end</span></code></pre></div>\n<p>In this example, each node in the trie is represented as a hash, with the keys being the characters and the values either another hash (representing a child node) or a boolean flag indicating the end of a word.</p>\n<h3>Lazy Loading: Minimizing the Initial Impact</h3>\n<p>While a trie-based autocomplete solution offers impressive performance benefits, the initial setup cost can be a concern, especially when dealing with large datasets. Imagine having to load millions of words into the trie when your application starts up - that’s a surefire way to slow down your application’s launch time and potentially overwhelm your server’s memory.</p>\n<p>To address this, we can implement a lazy loading approach, where we only populate the trie as needed, rather than loading everything upfront. Here’s how it might look in a Ruby on Rails context:</p>\n<div class=\"gatsby-highlight\" data-language=\"ruby\"><pre class=\"language-ruby\"><code class=\"language-ruby\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">Word</span> <span class=\"token operator\">&lt;</span> ApplicationRecord\n  <span class=\"token keyword\">class</span> <span class=\"token operator\">&lt;&lt;</span> <span class=\"token keyword\">self</span>\n    <span class=\"token keyword\">def</span> <span class=\"token method-definition\"><span class=\"token function\">trie</span></span>\n      <span class=\"token variable\">@@trie</span> <span class=\"token operator\">||=</span> <span class=\"token keyword\">begin</span>\n        trie <span class=\"token operator\">=</span> <span class=\"token class-name\">Trie</span><span class=\"token punctuation\">.</span><span class=\"token keyword\">new</span>\n        find_each <span class=\"token punctuation\">{</span> <span class=\"token operator\">|</span>word<span class=\"token operator\">|</span> trie<span class=\"token punctuation\">.</span>insert<span class=\"token punctuation\">(</span>word<span class=\"token punctuation\">.</span>name<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">}</span>\n        trie\n      <span class=\"token keyword\">end</span>\n    <span class=\"token keyword\">end</span>\n  <span class=\"token keyword\">end</span>\n<span class=\"token keyword\">end</span></code></pre></div>\n<p>In this implementation, the trie is initialized when the Word.trie method is first called. The find_each method is used to fetch the words from the database in batches, rather than loading them all at once. This helps minimize the initial memory footprint and startup time of the application.</p>\n<p>In this implementation, the trie is initialized when the <code class=\"language-text\">Word.trie</code> method is first called. The <code class=\"language-text\">find_each</code> method is used to fetch the words from the database in batches, rather than loading them all at once. This helps minimize the initial memory footprint and startup time of the application.</p>\n<h3>Batch Processing: Keeping the Trie Fresh</h3>\n<p>While lazy loading can help with the initial setup, as new words are added to the database, we need to ensure that the trie is kept up-to-date. One way to do this is to update the trie in batches, rather than performing individual updates for each new word.</p>\n<div class=\"gatsby-highlight\" data-language=\"ruby\"><pre class=\"language-ruby\"><code class=\"language-ruby\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">Word</span> <span class=\"token operator\">&lt;</span> ApplicationRecord\n  <span class=\"token keyword\">class</span> <span class=\"token operator\">&lt;&lt;</span> <span class=\"token keyword\">self</span>\n    <span class=\"token constant\">BATCH_SIZE</span> <span class=\"token operator\">=</span> <span class=\"token number\">10</span>_000\n\n    <span class=\"token keyword\">def</span> <span class=\"token method-definition\"><span class=\"token function\">trie</span></span>\n      <span class=\"token variable\">@@trie</span> <span class=\"token operator\">||=</span> <span class=\"token keyword\">begin</span>\n        trie <span class=\"token operator\">=</span> <span class=\"token class-name\">Trie</span><span class=\"token punctuation\">.</span><span class=\"token keyword\">new</span>\n        offset <span class=\"token operator\">=</span> <span class=\"token number\">0</span>\n        loop <span class=\"token keyword\">do</span>\n          words <span class=\"token operator\">=</span> pluck<span class=\"token punctuation\">(</span><span class=\"token symbol\">:name</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>offset<span class=\"token punctuation\">(</span>offset<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>limit<span class=\"token punctuation\">(</span><span class=\"token constant\">BATCH_SIZE</span><span class=\"token punctuation\">)</span>\n          <span class=\"token keyword\">break</span> <span class=\"token keyword\">if</span> words<span class=\"token punctuation\">.</span>empty<span class=\"token operator\">?</span>\n          words<span class=\"token punctuation\">.</span><span class=\"token keyword\">each</span> <span class=\"token punctuation\">{</span> <span class=\"token operator\">|</span>word<span class=\"token operator\">|</span> trie<span class=\"token punctuation\">.</span>insert<span class=\"token punctuation\">(</span>word<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">}</span>\n          offset <span class=\"token operator\">+=</span> <span class=\"token constant\">BATCH_SIZE</span>\n        <span class=\"token keyword\">end</span>\n        trie\n      <span class=\"token keyword\">end</span>\n    <span class=\"token keyword\">end</span>\n  <span class=\"token keyword\">end</span>\n<span class=\"token keyword\">end</span></code></pre></div>\n<p>In this example, we’re loading the words in batches of 10,000 records at a time, using the <code class=\"language-text\">offset</code> and <code class=\"language-text\">limit</code> methods to fetch the data in chunks. This approach can be further optimized by using a background job to load the data asynchronously, ensuring that the main application remains responsive.</p>\n<h3>Partitioning: Distributing the Load</h3>\n<p>As the size of your dataset continues to grow, even the batch processing approach may not be enough to maintain optimal performance. This is where partitioning the trie can be a game-changer.</p>\n<p>Instead of a single trie, we can create a partitioned trie, where each partition is responsible for a subset of the data. This allows us to distribute the load and improve the overall performance of the autocomplete functionality.</p>\n<div class=\"gatsby-highlight\" data-language=\"ruby\"><pre class=\"language-ruby\"><code class=\"language-ruby\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">Word</span> <span class=\"token operator\">&lt;</span> ApplicationRecord\n  <span class=\"token keyword\">class</span> <span class=\"token operator\">&lt;&lt;</span> <span class=\"token keyword\">self</span>\n    <span class=\"token keyword\">def</span> <span class=\"token method-definition\"><span class=\"token function\">trie</span></span>\n      <span class=\"token variable\">@@trie</span> <span class=\"token operator\">||=</span> <span class=\"token keyword\">begin</span>\n        trie <span class=\"token operator\">=</span> <span class=\"token class-name\">PartitionedTrie</span><span class=\"token punctuation\">.</span><span class=\"token keyword\">new</span>\n        find_each <span class=\"token punctuation\">{</span> <span class=\"token operator\">|</span>word<span class=\"token operator\">|</span> trie<span class=\"token punctuation\">.</span>insert<span class=\"token punctuation\">(</span>word<span class=\"token punctuation\">.</span>name<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">}</span>\n        trie\n      <span class=\"token keyword\">end</span>\n    <span class=\"token keyword\">end</span>\n  <span class=\"token keyword\">end</span>\n<span class=\"token keyword\">end</span>\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">PartitionedTrie</span>\n  <span class=\"token keyword\">def</span> <span class=\"token method-definition\"><span class=\"token function\">initialize</span></span>\n    <span class=\"token variable\">@tries</span> <span class=\"token operator\">=</span> <span class=\"token class-name\">Hash</span><span class=\"token punctuation\">.</span><span class=\"token keyword\">new</span> <span class=\"token punctuation\">{</span> <span class=\"token operator\">|</span>h<span class=\"token punctuation\">,</span> k<span class=\"token operator\">|</span> h<span class=\"token punctuation\">[</span>k<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token class-name\">Trie</span><span class=\"token punctuation\">.</span><span class=\"token keyword\">new</span> <span class=\"token punctuation\">}</span>\n  <span class=\"token keyword\">end</span>\n\n  <span class=\"token keyword\">def</span> <span class=\"token method-definition\"><span class=\"token function\">insert</span></span><span class=\"token punctuation\">(</span>word<span class=\"token punctuation\">)</span>\n    <span class=\"token variable\">@tries</span><span class=\"token punctuation\">[</span>word<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>insert<span class=\"token punctuation\">(</span>word<span class=\"token punctuation\">)</span>\n  <span class=\"token keyword\">end</span>\n\n  <span class=\"token keyword\">def</span> <span class=\"token method-definition\"><span class=\"token function\">autocomplete</span></span><span class=\"token punctuation\">(</span>prefix<span class=\"token punctuation\">,</span> <span class=\"token symbol\">page</span><span class=\"token operator\">:</span> <span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token symbol\">per_page</span><span class=\"token operator\">:</span> <span class=\"token number\">10</span><span class=\"token punctuation\">)</span>\n    trie <span class=\"token operator\">=</span> <span class=\"token variable\">@tries</span><span class=\"token punctuation\">[</span>prefix<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">]</span>\n    trie<span class=\"token punctuation\">.</span>autocomplete<span class=\"token punctuation\">(</span>prefix<span class=\"token punctuation\">,</span> <span class=\"token symbol\">page</span><span class=\"token operator\">:</span> page<span class=\"token punctuation\">,</span> <span class=\"token symbol\">per_page</span><span class=\"token operator\">:</span> per_page<span class=\"token punctuation\">)</span>\n  <span class=\"token keyword\">end</span>\n<span class=\"token keyword\">end</span></code></pre></div>\n<p>In this implementation, we use a <code class=\"language-text\">PartitionedTrie</code> class that maintains a hash of individual tries, partitioned by the first letter of the word. When inserting a word, we route it to the appropriate trie based on the first letter. When performing an autocomplete search, we only need to search the trie for the first letter of the prefix, which can significantly improve the performance for large datasets.</p>\n<p>You can further optimize the partitioning strategy based on your data distribution and access patterns. For example, you could partition by the first two letters, or use a more sophisticated hashing scheme to distribute the load more evenly.</p>\n<p>By combining the power of tries with performance-focused optimizations like lazy loading, batch processing, and partitioning, you can build an autocomplete solution that can handle even the largest of datasets with ease.</p>\n<p>This approach not only ensures that your users enjoy a lightning-fast search experience, but it also helps to keep your application’s resource utilization in check, even as your user base continues to grow.</p>\n<p>So, if you’re looking to take your Ruby on Rails application’s search capabilities to the next level, don’t hesitate to embrace the humble trie. With the right optimizations, it can be the key to unlocking blazing-fast autocomplete functionality</p>","frontmatter":{"title":"Autocomplete at Scale - How Tries and Partitioning Can Unlock Blazing-Fast Search in Ruby on Rails","date":"April 07, 2024"}}},"pageContext":{"slug":"/14-autocomplete-on-scale-with-ruby-on-rails/","previous":{"fields":{"slug":"/13-procs-lambdas-blocks/"},"frontmatter":{"title":"Procs, Lambdas and Blocks in Ruby on Rails"}},"next":{"fields":{"slug":"/15-mastering-decorator-pattern-ruby-on-rails/"},"frontmatter":{"title":"Mastering the decorator pattern in Ruby on Rails"}}}},"staticQueryHashes":["2418676009","3128451518"]}